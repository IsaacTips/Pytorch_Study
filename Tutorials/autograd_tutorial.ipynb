{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nAutograd: \uc790\ub3d9 \ubbf8\ubd84\n===================================\n\nPyTorch\uc758 \ubaa8\ub4e0 \uc2e0\uacbd\ub9dd\uc758 \uc911\uc2ec\uc5d0\ub294 ``autograd`` \ud328\ud0a4\uc9c0\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n\uba3c\uc800 \uc774\uac83\uc744 \uac00\ubccd\uac8c \uc0b4\ud3b4\ubcf8 \ub4a4, \uccab\ubc88\uc9f8 \uc2e0\uacbd\ub9dd\uc744 \ud559\uc2b5\uc2dc\ucf1c\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n``autograd`` \ud328\ud0a4\uc9c0\ub294 Tensor\uc758 \ubaa8\ub4e0 \uc5f0\uc0b0\uc5d0 \ub300\ud574 \uc790\ub3d9 \ubbf8\ubd84\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4.\n\uc774\ub294 \uc2e4\ud589-\uae30\ubc18-\uc815\uc758(define-by-run) \ud504\ub808\uc784\uc6cc\ud06c\ub85c, \uc774\ub294 \ucf54\ub4dc\ub97c \uc5b4\ub5bb\uac8c \uc791\uc131\ud558\uc5ec\n\uc2e4\ud589\ud558\ub290\ub0d0\uc5d0 \ub530\ub77c \uc5ed\uc804\ud30c\uac00 \uc815\uc758\ub41c\ub2e4\ub294 \ub73b\uc774\uba70, \uc5ed\uc804\ud30c\ub294 \ud559\uc2b5 \uacfc\uc815\uc758 \ub9e4 \ub2e8\uacc4\ub9c8\ub2e4\n\ub2ec\ub77c\uc9d1\ub2c8\ub2e4.\n\n\ub354 \uac04\ub2e8\ud55c \uc6a9\uc5b4\ub85c \uba87 \uac00\uc9c0 \uc608\ub97c \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\nTensor\n--------\n\n\ud328\ud0a4\uc9c0\uc758 \uc911\uc2ec\uc5d0\ub294 ``torch.Tensor`` \ud074\ub798\uc2a4\uac00 \uc788\uc2b5\ub2c8\ub2e4. \ub9cc\uc57d ``.requires_grad``\n\uc18d\uc131\uc744 ``True`` \ub85c \uc124\uc815\ud558\uba74, \uadf8 tensor\uc5d0\uc11c \uc774\ub904\uc9c4 \ubaa8\ub4e0 \uc5f0\uc0b0\ub4e4\uc744 \ucd94\uc801(track)\ud558\uae30\n\uc2dc\uc791\ud569\ub2c8\ub2e4. \uacc4\uc0b0\uc774 \uc644\ub8cc\ub41c \ud6c4 ``.backward()`` \ub97c \ud638\ucd9c\ud558\uc5ec \ubaa8\ub4e0 \ubcc0\ud654\ub3c4(gradient)\ub97c\n\uc790\ub3d9\uc73c\ub85c \uacc4\uc0b0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 Tensor\uc758 \ubcc0\ud654\ub3c4\ub294 ``.grad`` \uc18d\uc131\uc5d0 \ub204\uc801\ub429\ub2c8\ub2e4.\n\nTensor\uac00 \uae30\ub85d\uc744 \ucd94\uc801\ud558\ub294 \uac83\uc744 \uc911\ub2e8\ud558\uac8c \ud558\ub824\uba74, ``.detach()`` \ub97c \ud638\ucd9c\ud558\uc5ec \uc5f0\uc0b0\n\uae30\ub85d\uc73c\ub85c\ubd80\ud130 \ubd84\ub9ac(detach)\ud558\uc5ec \uc774\ud6c4 \uc5f0\uc0b0\ub4e4\uc774 \ucd94\uc801\ub418\ub294 \uac83\uc744 \ubc29\uc9c0\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uae30\ub85d\uc744 \ucd94\uc801\ud558\ub294 \uac83(\uacfc \uba54\ubaa8\ub9ac\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83)\uc744 \ubc29\uc9c0\ud558\uae30 \uc704\ud574, \ucf54\ub4dc \ube14\ub7ed\uc744\n``with torch.no_grad():`` \ub85c \uac10\uc300 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ud2b9\ud788 \ubcc0\ud654\ub3c4(gradient)\ub294\n\ud544\uc694\uc5c6\uc9c0\ub9cc, `requires_grad=True` \uac00 \uc124\uc815\ub418\uc5b4 \ud559\uc2b5 \uac00\ub2a5\ud55c \ub9e4\uac1c\ubcc0\uc218\ub97c \uac16\ub294 \ubaa8\ub378\uc744\n\ud3c9\uac00(evaluate)\ud560 \ub54c \uc720\uc6a9\ud569\ub2c8\ub2e4.\n\nAutograd \uad6c\ud604\uc5d0\uc11c \ub9e4\uc6b0 \uc911\uc694\ud55c \ud074\ub798\uc2a4\uac00 \ud558\ub098 \ub354 \uc788\ub294\ub370, \uc774\uac83\uc740 \ubc14\ub85c ``Function``\n\ud074\ub798\uc2a4\uc785\ub2c8\ub2e4.\n\n``Tensor`` \uc640 ``Function`` \uc740 \uc11c\ub85c \uc5f0\uacb0\ub418\uc5b4 \uc788\uc73c\uba70, \ubaa8\ub4e0 \uc5f0\uc0b0 \uacfc\uc815\uc744\n\ubd80\ud638\ud654(encode)\ud558\uc5ec \uc21c\ud658\ud558\uc9c0 \uc54a\ub294 \uadf8\ub798\ud504(acyclic graph)\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uac01 tensor\ub294\n``.grad_fn`` \uc18d\uc131\uc744 \uac16\uace0 \uc788\ub294\ub370, \uc774\ub294 ``Tensor`` \ub97c \uc0dd\uc131\ud55c ``Function`` \uc744\n\ucc38\uc870\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. (\ub2e8, \uc0ac\uc6a9\uc790\uac00 \ub9cc\ub4e0 Tensor\ub294 \uc608\uc678\ub85c, \uc774 \ub54c ``grad_fn`` \uc740\n``None`` \uc785\ub2c8\ub2e4.)\n\n\ub3c4\ud568\uc218\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574\uc11c\ub294 ``Tensor`` \uc758 ``.backward()`` \ub97c \ud638\ucd9c\ud558\uba74\n\ub429\ub2c8\ub2e4. \ub9cc\uc57d ``Tensor`` \uac00 \uc2a4\uce7c\ub77c(scalar)\uc778 \uacbd\uc6b0(\uc608. \ud558\ub098\uc758 \uc694\uc18c \uac12\ub9cc \uac16\ub294 \ub4f1)\uc5d0\ub294\n``backward`` \uc5d0 \uc778\uc790\ub97c \uc815\ud574\uc904 \ud544\uc694\uac00 \uc5c6\uc2b5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc5ec\ub7ec \uac1c\uc758 \uc694\uc18c\ub97c \uac16\uace0 \uc788\uc744\n\ub54c\ub294 tensor\uc758 \ubaa8\uc591\uc744 ``gradient`` \uc758 \uc778\uc790\ub85c \uc9c0\uc815\ud560 \ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "tensor\ub97c \uc0dd\uc131\ud558\uace0 ``requires_grad=True`` \ub97c \uc124\uc815\ud558\uc5ec \uc5f0\uc0b0\uc744 \uae30\ub85d\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\nprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "tensor\uc5d0 \uc5f0\uc0b0\uc744 \uc218\ud589\ud569\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = x + 2\nprint(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``y`` \ub294 \uc5f0\uc0b0\uc758 \uacb0\uacfc\ub85c \uc0dd\uc131\ub41c \uac83\uc774\ubbc0\ub85c ``grad_fn`` \uc744 \uac16\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(y.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``y`` \uc5d0 \ub2e4\ub978 \uc5f0\uc0b0\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = y * y * 3\nout = z.mean()\n\nprint(z, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``.requires_grad_( ... )`` \ub294 \uae30\uc874 Tensor\uc758 ``requires_grad`` \uac12\uc744 \ubc14\uafd4\uce58\uae30\n(in-place)\ud558\uc5ec \ubcc0\uacbd\ud569\ub2c8\ub2e4. \uc785\ub825\uac12\uc774 \uc9c0\uc815\ub418\uc9c0 \uc54a\uc73c\uba74 \uae30\ubcf8\uac12\uc740 ``False`` \uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = torch.randn(2, 2)\na = ((a * 3) / (a - 1))\nprint(a.requires_grad)\na.requires_grad_(True)\nprint(a.requires_grad)\nb = (a * a).sum()\nprint(b.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubcc0\ud654\ub3c4(Gradient)\n-----------------\n\uc774\uc81c \uc5ed\uc804\ud30c(backprop)\ub97c \ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n``out`` \uc740 \ud558\ub098\uc758 \uc2a4\uce7c\ub77c \uac12\ub9cc \uac16\uace0 \uc788\uae30 \ub54c\ubb38\uc5d0, ``out.backward()`` \ub294\n``out.backward(torch.tensor(1.))`` \uacfc \ub3d9\uc77c\ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubcc0\ud654\ub3c4 d(out)/dx\ub97c \ucd9c\ub825\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``4.5`` \ub85c \uc774\ub8e8\uc5b4\uc9c4 \ud589\ub82c\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. ``out`` \uc744 *Tensor* \u201c$o$\u201d\n\ub77c\uace0 \ud558\uba74, \ub2e4\uc74c\uacfc \uac19\uc774 \uad6c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n$o = \\frac{1}{4}\\sum_i z_i$ \uc774\uace0,\n$z_i = 3(x_i+2)^2$ \uc774\ubbc0\ub85c $z_i\\bigr\\rvert_{x_i=1} = 27$ \uc785\ub2c8\ub2e4.\n\ub530\ub77c\uc11c,\n$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$ \uc774\ubbc0\ub85c,\n$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$ \uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc218\ud559\uc801\uc73c\ub85c \ubca1\ud130 \ud568\uc218 $\\vec{y}=f(\\vec{x})$ \uc5d0\uc11c $\\vec{x}$ \uc5d0\n\ub300\ud55c $\\vec{y}$ \uc758 \ubcc0\ud654\ub3c4\ub294 \uc57c\ucf54\ube44\uc548 \ud589\ub82c(Jacobian Matrix)\uc785\ub2c8\ub2e4:\n\n\\begin{align}J=\\left(\\begin{array}{ccc}\n   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n   \\vdots & \\ddots & \\vdots\\\\\n   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n   \\end{array}\\right)\\end{align}\n\n\uc77c\ubc18\uc801\uc73c\ub85c, ``torch.autograd`` \ub294 \ubca1\ud130-\uc57c\ucf54\ube44\uc548 \uacf1\uc744 \uacc4\uc0b0\ud558\ub294 \uc5d4\uc9c4\uc785\ub2c8\ub2e4. \uc989,\n\uc5b4\ub5a4 \ubca1\ud130 $v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T}$\n\uc5d0 \ub300\ud574 $v^{T}\\cdot J$ \uc744 \uc5f0\uc0b0\ud569\ub2c8\ub2e4. \ub9cc\uc57d $v$ \uac00 \uc2a4\uce7c\ub77c \ud568\uc218\n$l=g\\left(\\vec{y}\\right)$ \uc758 \uae30\uc6b8\uae30\uc778 \uacbd\uc6b0,\n$v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$\n\uc774\uba70, \uc5f0\uc1c4\ubc95\uce59(chain rule)\uc5d0 \ub530\ub77c \ubca1\ud130-\uc57c\ucf54\ube44\uc548 \uacf1\uc740 $\\vec{x}$ \uc5d0 \ub300\ud55c\n$l$ \uc758 \uae30\uc6b8\uae30\uac00 \ub429\ub2c8\ub2e4:\n\n\\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n   \\vdots & \\ddots & \\vdots\\\\\n   \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n   \\end{array}\\right)\\left(\\begin{array}{c}\n   \\frac{\\partial l}{\\partial y_{1}}\\\\\n   \\vdots\\\\\n   \\frac{\\partial l}{\\partial y_{m}}\n   \\end{array}\\right)=\\left(\\begin{array}{c}\n   \\frac{\\partial l}{\\partial x_{1}}\\\\\n   \\vdots\\\\\n   \\frac{\\partial l}{\\partial x_{n}}\n   \\end{array}\\right)\\end{align}\n\n(\uc5ec\uae30\uc11c $v^{T}\\cdot J$ \uc740 $J^{T}\\cdot v$ \ub97c \ucde8\ud588\uc744 \ub54c\uc758 \uc5f4 \ubca1\ud130\ub85c\n\ucde8\uae09\ud560 \uc218 \uc788\ub294 \ud589 \ubca1\ud130\ub97c \uac16\uc2b5\ub2c8\ub2e4.)\n\n\ubca1\ud130-\uc57c\ucf54\ube44\uc548 \uacf1\uc758 \uc774\ub7ec\ud55c \ud2b9\uc131\uc740 \uc2a4\uce7c\ub77c\uac00 \uc544\ub2cc \ucd9c\ub825\uc744 \uac16\ub294 \ubaa8\ub378\uc5d0 \uc678\ubd80 \ubcc0\ud654\ub3c4\ub97c\n\uc81c\uacf5(feed)\ud558\ub294 \uac83\uc744 \ub9e4\uc6b0 \ud3b8\ub9ac\ud558\uac8c \ud574\uc90d\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c \ubca1\ud130-\uc57c\ucf54\ube44\uc548 \uacf1\uc758 \uc608\uc81c\ub97c \uc0b4\ud3b4\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.randn(3, requires_grad=True)\n\ny = x * 2\nwhile y.data.norm() < 1000:\n    y = y * 2\n\nprint(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \uacbd\uc6b0 ``y`` \ub294 \ub354 \uc774\uc0c1 \uc2a4\uce7c\ub77c \uac12\uc774 \uc544\ub2d9\ub2c8\ub2e4. ``torch.autograd`` \ub294\n\uc804\uccb4 \uc57c\ucf54\ube44\uc548\uc744 \uc9c1\uc811 \uacc4\uc0b0\ud560\uc218\ub294 \uc5c6\uc9c0\ub9cc, \ubca1\ud130-\uc57c\ucf54\ube44\uc548 \uacf1\uc740 \uac04\ub2e8\ud788\n``backward`` \uc5d0 \ud574\ub2f9 \ubca1\ud130\ub97c \uc778\uc790\ub85c \uc81c\uacf5\ud558\uc5ec \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\ny.backward(v)\n\nprint(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub610\ud55c ``with torch.no_grad():`` \ub85c \ucf54\ub4dc \ube14\ub7ed\uc744 \uac10\uc2f8\uc11c autograd\uac00\n``.requires_grad=True`` \uc778 Tensor\ub4e4\uc758 \uc5f0\uc0b0 \uae30\ub85d\uc744 \ucd94\uc801\ud558\ub294 \uac83\uc744 \uba48\ucd9c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(x.requires_grad)\nprint((x ** 2).requires_grad)\n\nwith torch.no_grad():\n\tprint((x ** 2).requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub610\ub294 ``.detach()`` \ub97c \ud638\ucd9c\ud558\uc5ec \ub0b4\uc6a9\ubb3c(content)\uc740 \uac19\uc9c0\ub9cc require_grad\uac00 \ub2e4\ub978\n\uc0c8\ub85c\uc6b4 Tensor\ub97c \uac00\uc838\uc635\ub2c8\ub2e4:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(x.requires_grad)\ny = x.detach()\nprint(y.requires_grad)\nprint(x.eq(y).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**\ub354 \uc77d\uc744\uac70\ub9ac:**\n\n``autograd.Function`` \uad00\ub828 \ubb38\uc11c\ub294 https://pytorch.org/docs/stable/autograd.html#function\n\uc5d0\uc11c \ucc3e\uc544\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}